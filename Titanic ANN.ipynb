{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cd9ZH81tWPGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b6e419-3b32-43c3-fc86-d41c9e26f36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "HwD_OK8EiA5K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "kO68848ciOT5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Qu6bTiaui0SG",
        "outputId": "dafeb127-a66e-4b5f-84f1-b1e0d6410458"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         1\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfb158fb-ad8a-4e99-abd1-07f1e0310e35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfb158fb-ad8a-4e99-abd1-07f1e0310e35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfb158fb-ad8a-4e99-abd1-07f1e0310e35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfb158fb-ad8a-4e99-abd1-07f1e0310e35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkZjYHT7i7LZ",
        "outputId": "3d528e43-cb96-473a-a8e4-f250f246676e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[[\"PassengerId\"]]"
      ],
      "metadata": {
        "id": "DCqj-qoTjHKp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df[\"Survived\"]"
      ],
      "metadata": {
        "id": "xINdkx0mjRxB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(2,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(8,activation='relu')) \n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "P81ZKnjujXIf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=150,batch_size=10,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_FgjTumjnSk",
        "outputId": "2565030d-82db-4f88-de88-f0cf570c9172"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "42/42 [==============================] - 1s 3ms/step - loss: 13.5505 - accuracy: 0.5000\n",
            "Epoch 2/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.5335\n",
            "Epoch 3/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.5813\n",
            "Epoch 4/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.5478\n",
            "Epoch 5/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8100 - accuracy: 0.5335\n",
            "Epoch 6/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.5431\n",
            "Epoch 7/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.5455\n",
            "Epoch 8/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8182 - accuracy: 0.5455\n",
            "Epoch 9/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8337 - accuracy: 0.5431\n",
            "Epoch 10/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8218 - accuracy: 0.5096\n",
            "Epoch 11/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.5144\n",
            "Epoch 12/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.5574\n",
            "Epoch 13/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.5478\n",
            "Epoch 14/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8002 - accuracy: 0.5383\n",
            "Epoch 15/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9047 - accuracy: 0.5048\n",
            "Epoch 16/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.5813\n",
            "Epoch 17/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7883 - accuracy: 0.5431\n",
            "Epoch 18/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.5431\n",
            "Epoch 19/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7641 - accuracy: 0.5335\n",
            "Epoch 20/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9424 - accuracy: 0.5574\n",
            "Epoch 21/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7270 - accuracy: 0.5431\n",
            "Epoch 22/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.5574\n",
            "Epoch 23/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8073 - accuracy: 0.4904\n",
            "Epoch 24/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1010 - accuracy: 0.4904\n",
            "Epoch 25/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8514 - accuracy: 0.5287\n",
            "Epoch 26/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8479 - accuracy: 0.5144\n",
            "Epoch 27/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.4904\n",
            "Epoch 28/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8099 - accuracy: 0.5622\n",
            "Epoch 29/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.6005\n",
            "Epoch 30/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.5239\n",
            "Epoch 31/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7867 - accuracy: 0.5431\n",
            "Epoch 32/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8508 - accuracy: 0.5287\n",
            "Epoch 33/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.5048\n",
            "Epoch 34/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.3258 - accuracy: 0.5526\n",
            "Epoch 35/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1722 - accuracy: 0.5574\n",
            "Epoch 36/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.5287\n",
            "Epoch 37/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.5526\n",
            "Epoch 38/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8502 - accuracy: 0.5502\n",
            "Epoch 39/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8198 - accuracy: 0.5718\n",
            "Epoch 40/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7735 - accuracy: 0.5574\n",
            "Epoch 41/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7936 - accuracy: 0.5144\n",
            "Epoch 42/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9557 - accuracy: 0.5144\n",
            "Epoch 43/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8187 - accuracy: 0.5144\n",
            "Epoch 44/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7555 - accuracy: 0.5191\n",
            "Epoch 45/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7916 - accuracy: 0.5096\n",
            "Epoch 46/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7741 - accuracy: 0.5239\n",
            "Epoch 47/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7703 - accuracy: 0.5335\n",
            "Epoch 48/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7318 - accuracy: 0.5622\n",
            "Epoch 49/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7794 - accuracy: 0.5335\n",
            "Epoch 50/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7666 - accuracy: 0.5000\n",
            "Epoch 51/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8407 - accuracy: 0.5335\n",
            "Epoch 52/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8701 - accuracy: 0.5239\n",
            "Epoch 53/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.5478\n",
            "Epoch 54/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2540 - accuracy: 0.5622\n",
            "Epoch 55/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8420 - accuracy: 0.5287\n",
            "Epoch 56/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8790 - accuracy: 0.5502\n",
            "Epoch 57/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9737 - accuracy: 0.5311\n",
            "Epoch 58/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.5335\n",
            "Epoch 59/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7937 - accuracy: 0.4761\n",
            "Epoch 60/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.5407\n",
            "Epoch 61/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7140 - accuracy: 0.5574\n",
            "Epoch 62/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5598\n",
            "Epoch 63/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.5478\n",
            "Epoch 64/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7622 - accuracy: 0.5670\n",
            "Epoch 65/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7527 - accuracy: 0.5000\n",
            "Epoch 66/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7362 - accuracy: 0.5574\n",
            "Epoch 67/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7951 - accuracy: 0.5574\n",
            "Epoch 68/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8173 - accuracy: 0.4856\n",
            "Epoch 69/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.2133 - accuracy: 0.5718\n",
            "Epoch 70/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7727 - accuracy: 0.5359\n",
            "Epoch 71/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7718 - accuracy: 0.5359\n",
            "Epoch 72/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7429 - accuracy: 0.5526\n",
            "Epoch 73/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8212 - accuracy: 0.5766\n",
            "Epoch 74/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7493 - accuracy: 0.5383\n",
            "Epoch 75/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.6005\n",
            "Epoch 76/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.5478\n",
            "Epoch 77/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7346 - accuracy: 0.5383\n",
            "Epoch 78/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8364 - accuracy: 0.5359\n",
            "Epoch 79/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8492 - accuracy: 0.5191\n",
            "Epoch 80/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.5335\n",
            "Epoch 81/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.4904\n",
            "Epoch 82/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9543 - accuracy: 0.5287\n",
            "Epoch 83/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8035 - accuracy: 0.4809\n",
            "Epoch 84/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7622 - accuracy: 0.5431\n",
            "Epoch 85/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.5335\n",
            "Epoch 86/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7221 - accuracy: 0.5096\n",
            "Epoch 87/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8072 - accuracy: 0.5335\n",
            "Epoch 88/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7890 - accuracy: 0.5287\n",
            "Epoch 89/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7322 - accuracy: 0.5550\n",
            "Epoch 90/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.5383\n",
            "Epoch 91/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7574 - accuracy: 0.5885\n",
            "Epoch 92/150\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7625 - accuracy: 0.5526\n",
            "Epoch 93/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.9070 - accuracy: 0.5335\n",
            "Epoch 94/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7754 - accuracy: 0.5383\n",
            "Epoch 95/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7807 - accuracy: 0.5526\n",
            "Epoch 96/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7956 - accuracy: 0.4641\n",
            "Epoch 97/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7110 - accuracy: 0.5813\n",
            "Epoch 98/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.8960 - accuracy: 0.4904\n",
            "Epoch 99/150\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7252 - accuracy: 0.5670\n",
            "Epoch 100/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7145 - accuracy: 0.5574\n",
            "Epoch 101/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7915 - accuracy: 0.5287\n",
            "Epoch 102/150\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.8715 - accuracy: 0.4952\n",
            "Epoch 103/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.5144\n",
            "Epoch 104/150\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7344 - accuracy: 0.5215\n",
            "Epoch 105/150\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.5766\n",
            "Epoch 106/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8364 - accuracy: 0.5287\n",
            "Epoch 107/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 1.1195 - accuracy: 0.5383\n",
            "Epoch 108/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7682 - accuracy: 0.5000\n",
            "Epoch 109/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8280 - accuracy: 0.5287\n",
            "Epoch 110/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7515 - accuracy: 0.5335\n",
            "Epoch 111/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7935 - accuracy: 0.5431\n",
            "Epoch 112/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.5000\n",
            "Epoch 113/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8331 - accuracy: 0.5670\n",
            "Epoch 114/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7620 - accuracy: 0.5167\n",
            "Epoch 115/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7875 - accuracy: 0.5383\n",
            "Epoch 116/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7756 - accuracy: 0.5311\n",
            "Epoch 117/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7166 - accuracy: 0.5718\n",
            "Epoch 118/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7581 - accuracy: 0.5191\n",
            "Epoch 119/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.5550\n",
            "Epoch 120/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7981 - accuracy: 0.5263\n",
            "Epoch 121/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8160 - accuracy: 0.5574\n",
            "Epoch 122/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.5431\n",
            "Epoch 123/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.5024\n",
            "Epoch 124/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7920 - accuracy: 0.5191\n",
            "Epoch 125/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.5478\n",
            "Epoch 126/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8074 - accuracy: 0.5167\n",
            "Epoch 127/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.9172 - accuracy: 0.5024\n",
            "Epoch 128/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.5598\n",
            "Epoch 129/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.5718\n",
            "Epoch 130/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7832 - accuracy: 0.5383\n",
            "Epoch 131/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.5478\n",
            "Epoch 132/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7842 - accuracy: 0.5383\n",
            "Epoch 133/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8338 - accuracy: 0.5000\n",
            "Epoch 134/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5789\n",
            "Epoch 135/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.5718\n",
            "Epoch 136/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.5191\n",
            "Epoch 137/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7949 - accuracy: 0.5383\n",
            "Epoch 138/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.5239\n",
            "Epoch 139/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7643 - accuracy: 0.5455\n",
            "Epoch 140/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7323 - accuracy: 0.5909\n",
            "Epoch 141/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.9571 - accuracy: 0.4809\n",
            "Epoch 142/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.5502\n",
            "Epoch 143/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.5766\n",
            "Epoch 144/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7652 - accuracy: 0.5407\n",
            "Epoch 145/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.5383\n",
            "Epoch 146/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.5837\n",
            "Epoch 147/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.5526\n",
            "Epoch 148/150\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7542 - accuracy: 0.5048\n",
            "Epoch 149/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.5431\n",
            "Epoch 150/150\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.8350 - accuracy: 0.5287\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2769e4dcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "351Uz_8HjvNH",
        "outputId": "81fd44ee-52c8-42ba-a9d5-d10e82741256"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 2)                 4         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 24        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109\n",
            "Trainable params: 109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores=model.evaluate(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD3k4316j4w2",
        "outputId": "1079979f-95fb-4f6d-9978-9a1e75b373e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.6005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x,y,epochs=150,validation_split=0.20,batch_size=10,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qNe4Yk0kAMm",
        "outputId": "cfafc045-7b1b-4ed4-8b57-0e4bd4e7c6b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 2/150\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 3/150\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 4/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 5/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 6/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 7/150\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 8/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 9/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 10/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 11/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 12/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 13/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 14/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 15/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 16/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 17/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 18/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 19/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 20/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 21/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 22/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 23/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 24/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 25/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 26/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 27/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 28/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 29/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 30/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 31/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 32/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 33/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 34/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 35/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 36/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 37/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 38/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 39/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 40/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 41/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 42/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 43/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 44/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 45/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 46/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 47/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 48/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 49/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 50/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 51/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 52/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 53/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 54/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 55/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 56/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 57/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6749 - val_accuracy: 0.5952\n",
            "Epoch 58/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 59/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 60/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 61/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 62/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 63/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 64/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 65/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 66/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 67/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 68/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 69/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 70/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 71/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 72/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 73/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 74/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 75/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 76/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 77/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 78/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 79/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 80/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 81/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 82/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 83/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 84/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 85/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 86/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 87/150\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 88/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 89/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 90/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 91/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 92/150\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 93/150\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 94/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 95/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 96/150\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 97/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 98/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 99/150\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 100/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 101/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 102/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 103/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 104/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 105/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 106/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 107/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 108/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 109/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 110/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 111/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 112/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 113/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 114/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 115/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 116/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 117/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 118/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 119/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 120/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 121/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 122/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 123/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 124/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 125/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 126/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 127/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 128/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 129/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 130/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 131/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 132/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 133/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 134/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 135/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 136/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 137/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 138/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 139/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 140/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 141/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 142/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 143/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 144/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 145/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 146/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 147/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 148/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 149/150\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n",
            "Epoch 150/150\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6018 - val_loss: 0.6750 - val_accuracy: 0.5952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "E6z5CjotkLeV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"],label=\"ValAccuracy\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "BQ7IAKLkkZvd",
        "outputId": "67630d65-62bb-4fe2-8beb-90752afb392c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0VqZqA71ke25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}